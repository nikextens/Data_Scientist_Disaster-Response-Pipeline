# Data_Scientist_Disaster-Response-Pipeline

This project is part of my Data Sciene Nanodegree project by Udacity. 

### Instructions:
1. Run the following commands in the project's root directory to set up your database and model.
    - To run ETL pipeline that cleans data and stores in database
        `python data/process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db`
    - To run ML pipeline that trains classifier and saves
        `python models/train_classifier.py data/DisasterResponse.db models/classifier.pkl`
2. Go to `app` directory: `cd app`
3. Run your web app: `python run.py`
4. Click the `PREVIEW` button to open the homepage

## Libraries
The developer needs to import the following libraries to run the analysis:
- sys
- numpy 
- pandas 
- sqlalchemy
- re
- nltk
- pickle
- sklearn
- json
- plotly
- flask

## Motivation for project
lorem ipsum

## Dataset
lorem ipsum

## Result
lorem ipsum

## Acknowledgments
Although the data are provided by Keggle, they are part of Airbnb Inside, and the original source can be found [here](http://insideairbnb.com/get-the-data/).




